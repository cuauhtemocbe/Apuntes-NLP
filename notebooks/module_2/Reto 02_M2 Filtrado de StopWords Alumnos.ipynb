{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC4JSh43njBM"
   },
   "source": [
    "# Reto 02 M2: Filtrado de StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsenLaSAnjBe"
   },
   "outputs": [],
   "source": [
    "# Asignación de StopWords predefinidas para idioma Español\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk._____.stopwords.words('spanish')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfn-TAvanjBn"
   },
   "outputs": [],
   "source": [
    "# Creamos un diccionario con el formato\n",
    "# {Veces_que_aparece_la_palabra: [Palabra1, Palbra2, Palabra3, etc..]}\n",
    "from os import listdir\n",
    "Palabras = []\n",
    "Textos = []\n",
    "\n",
    "path = 'Datasets/Textos_Stopwords/'\n",
    "\n",
    "for File in listdir(path):\n",
    "    # Escribir la RUTA COMPLETA de cada archivo\n",
    "    with open(path + _____, encoding=\"latin-1\") as Text:\n",
    "        # LEER el texto y pasar todo a minúsculas y reemplazar signos de puntuación \n",
    "        texto = Text._____().lower()\n",
    "        texto = \"\".join(char for char in texto if (_____.isalnum() or _____ == \" \"))\n",
    "        Textos.append(texto)\n",
    "        # Agregamos al diccionario de palabras, solo las que no sean StopWords\n",
    "        for palabra in texto.split():\n",
    "            if(palabra not in _____):\n",
    "                Palabras._____(palabra)\n",
    "    \n",
    "# Crear el diccionario con las frecuencias como claves y listas de palabras \n",
    "# correspondientes a cada frecuencia como valores\n",
    "Palabras_unicas = {}\n",
    "for unica in set(Palabras):\n",
    "    Frec = Palabras.count(_____)\n",
    "    # Preguntar si existe el elemento en el diccionario y si no, agregarlo\n",
    "    if(Palabras_unicas.get(Frec) == None):\n",
    "        Palabras_unicas._____(Frec, [unica])\n",
    "    else:\n",
    "        Palabras_unicas[Frec]._____(unica)\n",
    "print(Palabras_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EM1KN9HZnjB3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ploteo de la gráfica de palabras para cada frecuencia de repetición\n",
    "# Declarar la librería para plotear y los parámetros de la gráfica\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "# Extraer la cantidad de palabras de cada categoría\n",
    "Frecuencias = []\n",
    "for Lista in Palabras_unicas.values():\n",
    "    Frecuencias.append(len(Lista))\n",
    "\n",
    "# Parámetros de ploteo\n",
    "plt.bar(Palabras_unicas._____(), _____, color=['cornflowerblue', 'lightblue', 'steelblue'])  \n",
    "plt.ylabel('Palabras distintas')\n",
    "plt.xlabel('Cantidad de repeticiones')\n",
    "plt.title('Cantidad de palabras por cantidad de apariciones')\n",
    "plt.xticks(rotation=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uM6xhyytnjCJ"
   },
   "outputs": [],
   "source": [
    "# Impresión de las palabras que corresponden a cada frecuencia:\n",
    "# (Se suma +1 porque el primer índice debe ser 1 y no 0)\n",
    "for x in range(len(_____.keys())):\n",
    "    print(\"\\nPalabras que se repiten \" + str(x+1) + \" veces:\")\n",
    "    if(Palabras_unicas.get(x+1) != None):\n",
    "        print(set(Palabras_unicas[x+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNGqWxLMnjDi"
   },
   "outputs": [],
   "source": [
    "# Agregar palabras adicionales (Personalizadas) al diccionario de StopWords\n",
    "\n",
    "print(\"Cantidad de Stopwords:\", len(stop_words))\n",
    "\n",
    "nuevas_StopWords = ['si','no', 'hola', 'adios', 'a', 'ante', 'bajo', 'cabe', 'con', 'contra', 'de', 'desde']\n",
    "stop_words.extend(nuevas_StopWords)\n",
    "\n",
    "print(\"Cantidad nueva de Stopwords:\", len(_____))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método que toma un texto y regresa el texto SIN stopwords\n",
    "def filtro_stopwords(Texto, stopwords):\n",
    "    texto_final = \"\"\n",
    "    for word in Texto.split():\n",
    "        if _____.lower() not in _____:\n",
    "            texto_final += _____ + \" \"\n",
    "    return texto_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimirmos todos los textos sin StopWords\n",
    "i = 1\n",
    "for texto in Textos:\n",
    "    nuevo_texto = filtro_stopwords(_____, _____)\n",
    "    print(\"Texto\" + str(i)+ \":\")\n",
    "    print(nuevo_texto, \"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reto 02S2 Filtrado de StopWords Alumnos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
