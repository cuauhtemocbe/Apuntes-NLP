{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Okn5z1PPonbh"
   },
   "source": [
    "# Reto 02: Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j_jAALqKonbl"
   },
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import spacy\n",
    "\n",
    "# Cargamos núcleo de trabajo (Español)\n",
    "core_es = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xklhbMm-onbo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No|hay|caminos|para|la|paz|;|la|paz|es|el|camino|(|Mahatma|Gandhi|)|\n",
      " Tamaño frase: \t 16\n",
      " Vocabulario \t 14\n",
      "\n",
      "Para|más|información|,|enviar|un|correo|a|la|dirección|actumlogo@gmail.com|o|visita|la|página|http://www.sitiogenerico.com|!|\n",
      " Tamaño frase: \t 17\n",
      " Vocabulario \t 16\n",
      "\n",
      "Viaje|de|5|km|hasta|CDMX|,|Costos|de|viaje|en|Uber|$|125.50|\n",
      " Tamaño frase: \t 14\n",
      " Vocabulario \t 13\n",
      "\n",
      "Vamos|a|visitar|Edo|.|de|Veracruz|en|M.X.|el|año|que|sigue|\n",
      " Tamaño frase: \t 13\n",
      " Vocabulario \t 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Escribimos las frases con el formato Unicode para estandarizar signos de puntuación en una lista\n",
    "Frases = [core_es(u'No hay caminos para la paz; la paz es el camino (Mahatma Gandhi)'),\n",
    "          core_es(u'Para más información, enviar un correo a la dirección '\n",
    "                'actumlogo@gmail.com o visita la página http://www.sitiogenerico.com!'),\n",
    "          core_es(u'Viaje de 5km hasta CDMX, Costos de viaje en Uber $125.50'),\n",
    "          core_es(u'Vamos a visitar Edo. de Veracruz en M.X. el año que sigue')]\n",
    "\n",
    "# Separamos la frase por medio de | (Utilizando el comando end)\n",
    "for Frase in Frases:\n",
    "    for token in Frase:\n",
    "        # Traegamos el texto de cada token\n",
    "        print(token.text, end='|')\n",
    "    # Imprimimos la cantidad de Tokens y la cantidad de elementos en el vocabulario (Voc)\n",
    "    print(\"\\n Tamaño frase: \\t \" + str(len(Frase)) + \n",
    "          # Método count_by permite obtener la cantidad de elementos por atributo de una frase\n",
    "          \"\\n Vocabulario \\t \" + str(len(Frase.count_by(spacy.attrs.ORTH))), end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The exact verbatim text of a token\n",
    "# el número de elementos escritos diferente\n",
    "spacy.attrs.ORTH"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Reto_02 Tokenizacion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
